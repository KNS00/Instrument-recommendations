{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Text-processing of metadata and creating a content-based recommender system based on Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_table('test_new.tsv',sep='\\s+',header=0).sort_values(['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "train = pd.read_table('train_new.tsv',sep='\\s+',header=0).sort_values(['user_id', 'item_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python clean_metadata.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_og = pd.read_table('metadata_cleaned.tsv', sep='\\t', header=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00508JFE4</td>\n",
       "      <td>Behringer EUROPOWER EPQ900 Professional 900 Wa...</td>\n",
       "      <td>BEHRINGER EUROPOWER EPQ900. Professional 900-W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0B89ZSYS7</td>\n",
       "      <td>Shure SM7B Vocal Dynamic Microphone for Broadc...</td>\n",
       "      <td>The SM7B dynamic microphone has a smooth, flat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B01HY530RS</td>\n",
       "      <td>StewMac Guitar Tech Wrench Set</td>\n",
       "      <td>6 sizes guitar techs use all the time. These t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B006O64JMY</td>\n",
       "      <td>PylePro Full Size Electric Guitar Package w/ A...</td>\n",
       "      <td>Product Description. Get rocking with this beg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00502CTPW</td>\n",
       "      <td>3 Mini Color Violin Fingering Tape for Fretboa...</td>\n",
       "      <td>Finally, no more ugly masking tape!These plast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23979</th>\n",
       "      <td>B071RRDXPM</td>\n",
       "      <td>Dean EVO XM Solid Body Electric Guitar - Satin...</td>\n",
       "      <td>Dean's EVO XM is a perfect blend of vintage de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23980</th>\n",
       "      <td>B0CF1WHZRF</td>\n",
       "      <td>NUX Mighty Lite BT MKII Portable Desktop Model...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23981</th>\n",
       "      <td>B0B422HMZG</td>\n",
       "      <td>LAMSAM Fully Loaded Guitar Control Plate, Prew...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23982</th>\n",
       "      <td>B06XJDTC2N</td>\n",
       "      <td>Fender American Series Stratocaster Guitar Tun...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23983</th>\n",
       "      <td>B0C2MKP4Y6</td>\n",
       "      <td>Bikoney Guitar Stand 5-Tier for Acoustic, Elec...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23984 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          item_id                                              title  \\\n",
       "0      B00508JFE4  Behringer EUROPOWER EPQ900 Professional 900 Wa...   \n",
       "1      B0B89ZSYS7  Shure SM7B Vocal Dynamic Microphone for Broadc...   \n",
       "2      B01HY530RS                     StewMac Guitar Tech Wrench Set   \n",
       "3      B006O64JMY  PylePro Full Size Electric Guitar Package w/ A...   \n",
       "4      B00502CTPW  3 Mini Color Violin Fingering Tape for Fretboa...   \n",
       "...           ...                                                ...   \n",
       "23979  B071RRDXPM  Dean EVO XM Solid Body Electric Guitar - Satin...   \n",
       "23980  B0CF1WHZRF  NUX Mighty Lite BT MKII Portable Desktop Model...   \n",
       "23981  B0B422HMZG  LAMSAM Fully Loaded Guitar Control Plate, Prew...   \n",
       "23982  B06XJDTC2N  Fender American Series Stratocaster Guitar Tun...   \n",
       "23983  B0C2MKP4Y6  Bikoney Guitar Stand 5-Tier for Acoustic, Elec...   \n",
       "\n",
       "                                             description  \n",
       "0      BEHRINGER EUROPOWER EPQ900. Professional 900-W...  \n",
       "1      The SM7B dynamic microphone has a smooth, flat...  \n",
       "2      6 sizes guitar techs use all the time. These t...  \n",
       "3      Product Description. Get rocking with this beg...  \n",
       "4      Finally, no more ugly masking tape!These plast...  \n",
       "...                                                  ...  \n",
       "23979  Dean's EVO XM is a perfect blend of vintage de...  \n",
       "23980                                                NaN  \n",
       "23981                                                NaN  \n",
       "23982                                                NaN  \n",
       "23983                                                NaN  \n",
       "\n",
       "[23984 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_og"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5621</th>\n",
       "      <td>B0002D01KO</td>\n",
       "      <td>Epiphone Gigbag for Solidbody Electric Guitars</td>\n",
       "      <td>Gigbag Epiphone Solidbody Electric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item_id                                           title  \\\n",
       "5621  B0002D01KO  Epiphone Gigbag for Solidbody Electric Guitars   \n",
       "\n",
       "                             description  \n",
       "5621  Gigbag Epiphone Solidbody Electric  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_og[metadata_og['item_id'] == 'B0002D01KO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_table('metadata_cleaned.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "metadata = metadata.sort_values(['item_id', 'title', 'description'])\n",
    "metadata['description'] = metadata['description'].fillna(\"\".strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = metadata['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in description: 74053\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import math\n",
    "\n",
    "description_before_pre_processing = description.copy()\n",
    "\n",
    "vocab = set()\n",
    "for s in description_before_pre_processing:\n",
    "    words = word_tokenize(s, language=\"english\")\n",
    "    vocab.update(words)\n",
    "print(\"Total number of words in description:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmer.stem('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import string\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "metadata['description'] = metadata['description'].str.lower() # lowercasing \n",
    "metadata['description'] = metadata['description'].apply(word_tokenize, language=\"english\") #tokenizing\n",
    "english_stopwords = stopwords.words('english') + [char for char in string.punctuation]\n",
    "metadata['description'] = metadata['description'].apply(\n",
    "    lambda tokens: [token for token in tokens if token not in english_stopwords]\n",
    ") \n",
    "\n",
    "metadata['description_stemmed'] = metadata['description'].apply(lambda x: [stemmer.stem(elem) for elem in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52688"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab = set()\n",
    "metadata['description_stemmed'].apply(\n",
    "    lambda tokens: new_vocab.update(set(tokens)))\n",
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab = set()\n",
    "metadata['description'].apply(\n",
    "    lambda tokens: new_vocab.update(set(tokens)))\n",
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kasperschiller/opt/anaconda3/envs/WRSLabs/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def identity_tokenizer(tokens):\n",
    "    return tokens\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer=identity_tokenizer, lowercase=False, preprocessor=None)\n",
    "\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(metadata['description_stemmed'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    tfidf_matrix.toarray(),\n",
    "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
    "    index=metadata['item_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader\n",
    "word2vec_vectors = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_item_embedding(tokens, embeddings, embedding_size=300) -> float:\n",
    "    # we get embeddings for each word in the description\n",
    "    word_vectors = [embeddings[word] for word in tokens if word in embeddings]\n",
    "    if len(word_vectors) == 0: # non-trained word\n",
    "        return np.zeros(embedding_size) \n",
    "    # avg the word embeddings\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "\n",
    "# Compute item embeddings using Word2Vec\n",
    "metadata['description_embedded'] = (metadata['description'].apply(\" \".join).apply(\n",
    "    lambda tokens: get_item_embedding(tokens, word2vec_vectors)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "tfidf_cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "tfidf_cosine_sim_df = pd.DataFrame(\n",
    "    tfidf_cosine_sim,\n",
    "    index=metadata['item_id'],\n",
    "    columns=metadata['item_id']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Cosine Similarity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>B0002D01KO</th>\n",
       "      <th>B0002D0CCQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0002D01KO</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002D0CCQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id     B0002D01KO  B0002D0CCQ\n",
       "item_id                           \n",
       "B0002D01KO         1.0         0.0\n",
       "B0002D0CCQ         0.0         1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"TF-IDF Cosine Similarity:\")\n",
    "ref_items = ['B0002D01KO', 'B0002D0CCQ']\n",
    "tfidf_cosine_sim_df[tfidf_cosine_sim_df.index.isin(ref_items)][ref_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23984, 52688)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>B0002D01KO</th>\n",
       "      <th>B0002D0CCQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0002D01KO</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002D0CCQ</th>\n",
       "      <td>0.977438</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id     B0002D01KO  B0002D0CCQ\n",
       "item_id                           \n",
       "B0002D01KO    1.000000    0.977438\n",
       "B0002D0CCQ    0.977438    1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "item_embeddings = np.vstack(metadata['description_embedded'].values)\n",
    "\n",
    "embedding_cosine_sim = cosine_similarity(item_embeddings)\n",
    "\n",
    "embedding_cosine_sim_df = pd.DataFrame(\n",
    "    embedding_cosine_sim,\n",
    "    index=metadata['item_id'],\n",
    "    columns=metadata['item_id']\n",
    ")\n",
    "embedding_cosine_sim_df[embedding_cosine_sim_df.index.isin(ref_items)][ref_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec similarity:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item_id</th>\n",
       "      <th>B0002D01KO</th>\n",
       "      <th>B0002D0CCQ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>item_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B0002D01KO</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B0002D0CCQ</th>\n",
       "      <td>0.977438</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "item_id     B0002D01KO  B0002D0CCQ\n",
       "item_id                           \n",
       "B0002D01KO    1.000000    0.977438\n",
       "B0002D0CCQ    0.977438    1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Word2Vec similarity:')\n",
    "embedding_cosine_sim_df[embedding_cosine_sim_df.index.isin(ref_items)][ref_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Title column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['title'] = metadata['title'].fillna(\"\".strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in title: 33193\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "title = metadata['title']\n",
    "\n",
    "titles_before_preprocessing = title.copy()\n",
    "\n",
    "vocab = set()\n",
    "for s in titles_before_preprocessing:\n",
    "    #words = str.split(\" \")\n",
    "    words = word_tokenize(s, language=\"english\")\n",
    "    vocab.update(words)\n",
    "print(\"Total number of words in title:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import string\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "metadata['title'] = metadata['title'].str.lower() # lowercasing \n",
    "metadata['title'] = metadata['title'].apply(word_tokenize, language=\"english\") #tokenizing\n",
    "english_stopwords = stopwords.words('english') + [char for char in string.punctuation]\n",
    "metadata['title'] = metadata['title'].apply(\n",
    "    lambda tokens: [token for token in tokens if token not in english_stopwords]\n",
    ") # remove stopwords\n",
    "\n",
    "metadata['title_stemmed'] = metadata['title'].apply(lambda x: [stemmer.stem(elem) for elem in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27962"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab = set()\n",
    "metadata['title_stemmed'].apply(\n",
    "    lambda tokens: new_vocab.update(set(tokens)))\n",
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29987"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vocab = set()\n",
    "metadata['title'].apply(\n",
    "    lambda tokens: new_vocab.update(set(tokens)))\n",
    "len(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec\n",
    "metadata['title_embedded'] = (metadata['title'].apply(\" \".join).apply(\n",
    "    lambda tokens: get_item_embedding(tokens, word2vec_vectors)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_test = test[test['rating'].apply(lambda x: x >= 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(user_id : str, sim_user_item_df : pd.DataFrame, k=10):\n",
    "    similarities = sim_user_item_df[user_id].sort_values(ascending=False, kind='stable')\n",
    "    return similarities.index[:k]\n",
    "\n",
    "def compute_precision_at_k(top_recs, ground_truth, k):\n",
    "    top_recs = top_recs[:k]\n",
    "    ground_truth = ground_truth\n",
    "    hits = len(set(top_recs) & set(ground_truth))\n",
    "    return hits / k\n",
    "\n",
    "def compute_ap(top_recs, ground_truth):\n",
    "    ground_truth_set = set(ground_truth)    \n",
    "    G = len(ground_truth_set)\n",
    "    if G == 0:\n",
    "        return 0.0\n",
    "    cumulative_precision = 0.0\n",
    "    relevant_count = 0\n",
    "    for rank, item in enumerate(top_recs, 1):\n",
    "        if item in ground_truth_set:\n",
    "            relevant_count += 1\n",
    "            precision_at_k = relevant_count / rank  # P@k\n",
    "            cumulative_precision += precision_at_k  # Sum of P@k for relevant ranks\n",
    "    ap = cumulative_precision / G\n",
    "    return ap\n",
    "def compute_metrics(user_ids, sim_user_item, k=10):\n",
    "    hit_rates = []\n",
    "    precision_scores = []\n",
    "    aps = []\n",
    "    rrs = []\n",
    "    total_items_in_catalog = len(set(train['item_id']).union(set(test['item_id'])))\n",
    "    recommended_items = set()\n",
    "    for user_id in user_ids:\n",
    "        hit = False\n",
    "        top_recs = get_top_recommendations(user_id, sim_user_item, k)\n",
    "        recommended_items.update(list(top_recs))\n",
    "        ground_truth = list(relevant_test[relevant_test['user_id'] == user_id]['item_id'])\n",
    "        hits = len(set(top_recs) & set(ground_truth))\n",
    "        hit = (hits > 0).real\n",
    "        precision_at_k = compute_precision_at_k(top_recs, ground_truth, k)    \n",
    "        ap = compute_ap(top_recs, ground_truth)\n",
    "\n",
    "        for rank, item in enumerate(top_recs, 1):\n",
    "            if item in ground_truth:\n",
    "                rr = 1 / rank\n",
    "                break\n",
    "            else:\n",
    "                rr = 0\n",
    "        \n",
    "        coverage =  len(recommended_items) / total_items_in_catalog\n",
    "        hit_rates.append(hit)\n",
    "        precision_scores.append(precision_at_k)\n",
    "        aps.append(ap)\n",
    "        rrs.append(rr)\n",
    "    return {'PRECISION@k:': round(np.mean(precision_scores), 3), 'MAP@k:': round(np.mean(aps), 3), 'MRR@k:': round(np.mean(rrs), 3), 'Hit rate': round(np.mean(hit_rates), 3), 'Coverage': round(coverage, 3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_new = metadata[metadata['item_id'].isin(set(train['item_id']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PRECISION@k:': 0.011, 'MAP@k:': 0.008, 'MRR@k:': 0.035, 'Hit rate': 0.096, 'Coverage': 0.4}\n"
     ]
    }
   ],
   "source": [
    "title_features = np.array(metadata_new['title_embedded'].tolist())\n",
    "description_features = np.array(metadata_new['description_embedded'].tolist())\n",
    "\n",
    "title_features_dict = {item_id: feature_vector for item_id, feature_vector in zip(metadata_new['item_id'], metadata_new['title_embedded'])}\n",
    "description_features_dict = {item_id: feature_vector for item_id, feature_vector in zip(metadata_new['item_id'], metadata_new['description_embedded'])}\n",
    "\n",
    "user_profiles = pd.DataFrame(index=train['user_id'].unique())\n",
    "user_profiles['title_profile'] = None  \n",
    "user_profiles['description_profile'] = None  \n",
    "\n",
    "user_profiles['title_profile'] = user_profiles['title_profile'].astype(object)\n",
    "user_profiles['description_profile'] = user_profiles['description_profile'].astype(object)\n",
    "\n",
    "for user_id, group in train.groupby('user_id'):\n",
    "\n",
    "    title_vector = np.average([title_features_dict.get(key) for key in group['item_id']], axis=0, weights=group['rating'])\n",
    "    description_vector = np.average([description_features_dict.get(key) for key in group['item_id']], axis=0, weights=group['rating'])\n",
    "    \n",
    "    user_profiles.at[user_id, 'title_profile'] = title_vector.tolist()  \n",
    "    user_profiles.at[user_id, 'description_profile'] = description_vector.tolist()\n",
    "title_sim = cosine_similarity(title_features, list(user_profiles['title_profile']))\n",
    "title_sim_df = pd.DataFrame(title_sim, index=metadata_new['item_id'], columns=user_profiles.index)\n",
    "\n",
    "description_sim = cosine_similarity(description_features, list(user_profiles['description_profile']))\n",
    "description_sim_df = pd.DataFrame(description_sim, index=metadata_new['item_id'], columns=user_profiles.index)\n",
    "\n",
    "\n",
    "#alphas = [0, 1/3, 2/3, 1]\n",
    "for alpha in [2/3]:\n",
    "    combined_sim = alpha * title_sim_df + (1 - alpha) * description_sim_df \n",
    "    metrics = compute_metrics(relevant_test['user_id'].unique(), sim_user_item=combined_sim, k=10)\n",
    "    print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sim_dict = combined_sim.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_sim_dict_sorted = {\n",
    "    user: dict(sorted(items.items(), key=lambda x: x[1], reverse=True))\n",
    "    for user, items in combined_sim_dict.items()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('collab_rankings.json', 'w') as fp:\n",
    "    json.dump(combined_sim_dict_sorted, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_to_rating_range(similarity_scores):\n",
    "    normalized_scores = 1 + (similarity_scores - 0) * (4 / (1 - 0)) \n",
    "    return normalized_scores\n",
    "\n",
    "normalized_ratings = normalize_to_rating_range(combined_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to sort in this way to keep the sorting of identical ratings from the original models DataFrame.\n",
    "normalized_ratings_dict = normalized_ratings.to_dict()\n",
    "\n",
    "combined_sim_df = pd.DataFrame(normalized_ratings_dict)\n",
    "\n",
    "normalized_ratings_sorted = {}\n",
    "for user in combined_sim_df.columns:\n",
    "    user_ratings = combined_sim_df[user]\n",
    "    \n",
    "    sorted_items = user_ratings.sort_values(ascending=False, kind='stable').index.tolist()\n",
    "    \n",
    "    normalized_ratings_sorted[user] = {item: user_ratings[item] for item in sorted_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('content_rankings_with_rating.json', 'w') as fp:\n",
    "    json.dump(normalized_ratings_sorted, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WRSLabs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
